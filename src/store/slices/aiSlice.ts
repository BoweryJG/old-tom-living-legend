import { createSlice, createAsyncThunk, PayloadAction } from '@reduxjs/toolkit';\nimport { aiIntegrationService } from '@/services/aiIntegrationService';\nimport { speechRecognitionService } from '@/services/speechRecognitionService';\nimport { privacyService } from '@/services/privacyService';\n\ninterface AIState {\n  // Current AI Interaction\n  currentInteraction: {\n    active: boolean;\n    type: 'question' | 'command' | 'exploration' | 'casual_chat' | null;\n    character: 'old-tom' | 'george-davidson' | 'child-narrator' | null;\n    method: 'voice' | 'text' | 'mixed';\n    processing: boolean;\n    error: string | null;\n  };\n  \n  // Speech Recognition\n  speechRecognition: {\n    supported: boolean;\n    listening: boolean;\n    transcript: string;\n    confidence: number;\n    lastCommand: {\n      type: string;\n      action: string;\n      parameters: Record<string, any>;\n    } | null;\n    error: string | null;\n  };\n  \n  // Voice Synthesis\n  voiceSynthesis: {\n    speaking: boolean;\n    queue: Array<{\n      id: string;\n      text: string;\n      character: string;\n      emotion: string;\n      priority: 'low' | 'medium' | 'high';\n    }>;\n    currentAudio: {\n      id: string;\n      character: string;\n      duration: number;\n      startTime: number;\n    } | null;\n    settings: {\n      enabled: boolean;\n      volume: number;\n      rate: number;\n      autoPlay: boolean;\n    };\n  };\n  \n  // Emotional AI\n  emotionalAnalysis: {\n    currentEmotion: {\n      primary: string;\n      secondary?: string;\n      intensity: number;\n      confidence: number;\n      timestamp: number;\n    } | null;\n    emotionHistory: Array<{\n      emotion: string;\n      intensity: number;\n      timestamp: number;\n    }>;\n    supportLevel: 'minimal' | 'moderate' | 'high';\n    adaptations: {\n      voiceSettings: any;\n      contentAdjustments: string[];\n      interactionStyle: string;\n    };\n    safetyAlerts: string[];\n  };\n  \n  // Conversation Memory\n  conversationContext: {\n    sessionId: string;\n    relationshipLevel: 'stranger' | 'acquaintance' | 'friend' | 'trusted_friend';\n    previousTopics: string[];\n    totalInteractions: number;\n    sessionStartTime: number;\n    lastInteractionTime: number;\n    learningProgress: Record<string, number>;\n    personalPreferences: {\n      favoriteTopics: string[];\n      communicationStyle: 'visual' | 'auditory' | 'interactive';\n      attentionSpan: 'short' | 'medium' | 'long';\n    };\n  };\n  \n  // Privacy & Consent\n  privacy: {\n    consentGiven: boolean;\n    parentalConsentRequired: boolean;\n    dataProcessingAllowed: {\n      voice: boolean;\n      emotion: boolean;\n      learning: boolean;\n      memory: boolean;\n    };\n    dataRetentionSettings: {\n      sessionData: number;\n      personalData: number;\n    };\n  };\n  \n  // Performance & Caching\n  performance: {\n    averageResponseTime: number;\n    cacheHitRate: number;\n    offlineMode: boolean;\n    networkStatus: 'online' | 'offline' | 'slow';\n    serviceHealth: {\n      openai: 'healthy' | 'degraded' | 'offline';\n      elevenlabs: 'healthy' | 'degraded' | 'offline';\n      memory: 'healthy' | 'degraded' | 'offline';\n    };\n  };\n  \n  // Learning & Recommendations\n  learning: {\n    currentTopics: string[];\n    achievements: Array<{\n      id: string;\n      title: string;\n      description: string;\n      timestamp: number;\n    }>;\n    recommendations: {\n      suggestedTopics: string[];\n      learningObjectives: string[];\n      characterRecommendations: string[];\n    };\n    difficultyLevel: 'simple' | 'moderate' | 'complex';\n  };\n  \n  // Navigation & Follow-up\n  navigation: {\n    suggestions: string[];\n    autoNavigation: {\n      enabled: boolean;\n      pendingNavigation: {\n        page: string;\n        reason: string;\n        timestamp: number;\n      } | null;\n    };\n    contextualPrompts: string[];\n  };\n}\n\nconst initialState: AIState = {\n  currentInteraction: {\n    active: false,\n    type: null,\n    character: null,\n    method: 'text',\n    processing: false,\n    error: null\n  },\n  speechRecognition: {\n    supported: false,\n    listening: false,\n    transcript: '',\n    confidence: 0,\n    lastCommand: null,\n    error: null\n  },\n  voiceSynthesis: {\n    speaking: false,\n    queue: [],\n    currentAudio: null,\n    settings: {\n      enabled: true,\n      volume: 0.8,\n      rate: 1.0,\n      autoPlay: true\n    }\n  },\n  emotionalAnalysis: {\n    currentEmotion: null,\n    emotionHistory: [],\n    supportLevel: 'minimal',\n    adaptations: {\n      voiceSettings: {},\n      contentAdjustments: [],\n      interactionStyle: 'supportive'\n    },\n    safetyAlerts: []\n  },\n  conversationContext: {\n    sessionId: '',\n    relationshipLevel: 'stranger',\n    previousTopics: [],\n    totalInteractions: 0,\n    sessionStartTime: Date.now(),\n    lastInteractionTime: 0,\n    learningProgress: {},\n    personalPreferences: {\n      favoriteTopics: [],\n      communicationStyle: 'interactive',\n      attentionSpan: 'medium'\n    }\n  },\n  privacy: {\n    consentGiven: false,\n    parentalConsentRequired: false,\n    dataProcessingAllowed: {\n      voice: false,\n      emotion: false,\n      learning: true,\n      memory: true\n    },\n    dataRetentionSettings: {\n      sessionData: 24,\n      personalData: 7\n    }\n  },\n  performance: {\n    averageResponseTime: 0,\n    cacheHitRate: 0,\n    offlineMode: false,\n    networkStatus: 'online',\n    serviceHealth: {\n      openai: 'healthy',\n      elevenlabs: 'healthy',\n      memory: 'healthy'\n    }\n  },\n  learning: {\n    currentTopics: [],\n    achievements: [],\n    recommendations: {\n      suggestedTopics: [],\n      learningObjectives: [],\n      characterRecommendations: []\n    },\n    difficultyLevel: 'simple'\n  },\n  navigation: {\n    suggestions: [],\n    autoNavigation: {\n      enabled: false,\n      pendingNavigation: null\n    },\n    contextualPrompts: []\n  }\n};\n\n// Async Thunks\nexport const processAIInteraction = createAsyncThunk(\n  'ai/processInteraction',\n  async (request: {\n    input: { text?: string; voice?: any; context?: string };\n    interaction: { type: string; character: string; method: string };\n    userProfile: { age?: number; emotionalState?: string };\n    environment: { currentPage: string; sessionDuration: number };\n  }, { getState, rejectWithValue }) => {\n    try {\n      const state = getState() as { ai: AIState };\n      \n      const aiRequest = {\n        sessionId: state.ai.conversationContext.sessionId,\n        userId: 'user_' + state.ai.conversationContext.sessionId,\n        input: request.input,\n        interaction: {\n          type: request.interaction.type as any,\n          character: request.interaction.character as any,\n          method: request.interaction.method as any\n        },\n        userProfile: {\n          age: request.userProfile.age,\n          preferences: state.ai.conversationContext.personalPreferences,\n          emotionalState: request.userProfile.emotionalState\n        },\n        environment: {\n          currentPage: request.environment.currentPage,\n          sessionDuration: request.environment.sessionDuration,\n          timeOfDay: new Date().getHours() < 12 ? 'morning' as const : \n                    new Date().getHours() < 18 ? 'afternoon' as const : 'evening' as const\n        }\n      };\n      \n      const response = await aiIntegrationService.processAIInteraction(aiRequest);\n      return response;\n    } catch (error) {\n      return rejectWithValue((error as Error).message);\n    }\n  }\n);\n\nexport const startSpeechRecognition = createAsyncThunk(\n  'ai/startSpeechRecognition',\n  async (context: string = 'general', { rejectWithValue }) => {\n    try {\n      speechRecognitionService.setContext(context);\n      await speechRecognitionService.startListening();\n      return { context };\n    } catch (error) {\n      return rejectWithValue((error as Error).message);\n    }\n  }\n);\n\nexport const stopSpeechRecognition = createAsyncThunk(\n  'ai/stopSpeechRecognition',\n  async (_, { rejectWithValue }) => {\n    try {\n      speechRecognitionService.stopListening();\n      return {};\n    } catch (error) {\n      return rejectWithValue((error as Error).message);\n    }\n  }\n);\n\nexport const requestPrivacyConsent = createAsyncThunk(\n  'ai/requestPrivacyConsent',\n  async (params: { \n    childAge: number; \n    requiredConsents: string[]; \n    parentEmail?: string; \n  }, { getState, rejectWithValue }) => {\n    try {\n      const state = getState() as { ai: AIState };\n      const userId = 'user_' + state.ai.conversationContext.sessionId;\n      \n      const response = await privacyService.requestConsent(\n        userId,\n        params.childAge,\n        params.requiredConsents,\n        params.parentEmail\n      );\n      \n      return response;\n    } catch (error) {\n      return rejectWithValue((error as Error).message);\n    }\n  }\n);\n\nconst aiSlice = createSlice({\n  name: 'ai',\n  initialState,\n  reducers: {\n    // Session Management\n    initializeAISession: (state, action: PayloadAction<{ sessionId: string; childAge?: number }>) => {\n      state.conversationContext.sessionId = action.payload.sessionId;\n      state.conversationContext.sessionStartTime = Date.now();\n      state.conversationContext.totalInteractions = 0;\n      \n      // Initialize speech recognition support\n      state.speechRecognition.supported = speechRecognitionService.isSupported();\n      \n      // Set age-appropriate difficulty\n      if (action.payload.childAge) {\n        if (action.payload.childAge <= 5) {\n          state.learning.difficultyLevel = 'simple';\n        } else if (action.payload.childAge <= 8) {\n          state.learning.difficultyLevel = 'moderate';\n        } else {\n          state.learning.difficultyLevel = 'complex';\n        }\n      }\n    },\n    \n    // Interaction State\n    startInteraction: (state, action: PayloadAction<{\n      type: AIState['currentInteraction']['type'];\n      character: AIState['currentInteraction']['character'];\n      method: AIState['currentInteraction']['method'];\n    }>) => {\n      state.currentInteraction = {\n        active: true,\n        type: action.payload.type,\n        character: action.payload.character,\n        method: action.payload.method,\n        processing: false,\n        error: null\n      };\n    },\n    \n    endInteraction: (state) => {\n      state.currentInteraction = {\n        active: false,\n        type: null,\n        character: null,\n        method: 'text',\n        processing: false,\n        error: null\n      };\n    },\n    \n    setInteractionProcessing: (state, action: PayloadAction<boolean>) => {\n      state.currentInteraction.processing = action.payload;\n    },\n    \n    setInteractionError: (state, action: PayloadAction<string | null>) => {\n      state.currentInteraction.error = action.payload;\n      state.currentInteraction.processing = false;\n    },\n    \n    // Speech Recognition\n    setSpeechTranscript: (state, action: PayloadAction<{ transcript: string; confidence: number }>) => {\n      state.speechRecognition.transcript = action.payload.transcript;\n      state.speechRecognition.confidence = action.payload.confidence;\n    },\n    \n    setSpeechCommand: (state, action: PayloadAction<{\n      type: string;\n      action: string;\n      parameters: Record<string, any>;\n    }>) => {\n      state.speechRecognition.lastCommand = action.payload;\n    },\n    \n    setSpeechError: (state, action: PayloadAction<string | null>) => {\n      state.speechRecognition.error = action.payload;\n      state.speechRecognition.listening = false;\n    },\n    \n    // Voice Synthesis\n    addToVoiceQueue: (state, action: PayloadAction<{\n      id: string;\n      text: string;\n      character: string;\n      emotion: string;\n      priority: 'low' | 'medium' | 'high';\n    }>) => {\n      const newItem = action.payload;\n      \n      // Insert based on priority\n      if (newItem.priority === 'high') {\n        state.voiceSynthesis.queue.unshift(newItem);\n      } else {\n        state.voiceSynthesis.queue.push(newItem);\n      }\n    },\n    \n    removeFromVoiceQueue: (state, action: PayloadAction<string>) => {\n      state.voiceSynthesis.queue = state.voiceSynthesis.queue.filter(\n        item => item.id !== action.payload\n      );\n    },\n    \n    setCurrentAudio: (state, action: PayloadAction<{\n      id: string;\n      character: string;\n      duration: number;\n    } | null>) => {\n      if (action.payload) {\n        state.voiceSynthesis.currentAudio = {\n          ...action.payload,\n          startTime: Date.now()\n        };\n        state.voiceSynthesis.speaking = true;\n      } else {\n        state.voiceSynthesis.currentAudio = null;\n        state.voiceSynthesis.speaking = false;\n      }\n    },\n    \n    updateVoiceSettings: (state, action: PayloadAction<Partial<AIState['voiceSynthesis']['settings']>>) => {\n      state.voiceSynthesis.settings = {\n        ...state.voiceSynthesis.settings,\n        ...action.payload\n      };\n    },\n    \n    // Emotional Analysis\n    updateCurrentEmotion: (state, action: PayloadAction<{\n      primary: string;\n      secondary?: string;\n      intensity: number;\n      confidence: number;\n    }>) => {\n      const newEmotion = {\n        ...action.payload,\n        timestamp: Date.now()\n      };\n      \n      state.emotionalAnalysis.currentEmotion = newEmotion;\n      \n      // Add to history\n      state.emotionalAnalysis.emotionHistory.push({\n        emotion: newEmotion.primary,\n        intensity: newEmotion.intensity,\n        timestamp: newEmotion.timestamp\n      });\n      \n      // Keep only last 20 emotions\n      if (state.emotionalAnalysis.emotionHistory.length > 20) {\n        state.emotionalAnalysis.emotionHistory = \n          state.emotionalAnalysis.emotionHistory.slice(-20);\n      }\n    },\n    \n    updateEmotionalAdaptations: (state, action: PayloadAction<{\n      voiceSettings: any;\n      contentAdjustments: string[];\n      interactionStyle: string;\n    }>) => {\n      state.emotionalAnalysis.adaptations = action.payload;\n    },\n    \n    setSupportLevel: (state, action: PayloadAction<'minimal' | 'moderate' | 'high'>) => {\n      state.emotionalAnalysis.supportLevel = action.payload;\n    },\n    \n    addSafetyAlert: (state, action: PayloadAction<string>) => {\n      if (!state.emotionalAnalysis.safetyAlerts.includes(action.payload)) {\n        state.emotionalAnalysis.safetyAlerts.push(action.payload);\n      }\n    },\n    \n    clearSafetyAlerts: (state) => {\n      state.emotionalAnalysis.safetyAlerts = [];\n    },\n    \n    // Conversation Context\n    updateConversationContext: (state, action: PayloadAction<{\n      relationshipLevel?: AIState['conversationContext']['relationshipLevel'];\n      previousTopics?: string[];\n      learningProgress?: Record<string, number>;\n      personalPreferences?: Partial<AIState['conversationContext']['personalPreferences']>;\n    }>) => {\n      if (action.payload.relationshipLevel) {\n        state.conversationContext.relationshipLevel = action.payload.relationshipLevel;\n      }\n      \n      if (action.payload.previousTopics) {\n        // Add new topics, keep unique, limit to last 10\n        const allTopics = [...state.conversationContext.previousTopics, ...action.payload.previousTopics];\n        state.conversationContext.previousTopics = [...new Set(allTopics)].slice(-10);\n      }\n      \n      if (action.payload.learningProgress) {\n        state.conversationContext.learningProgress = {\n          ...state.conversationContext.learningProgress,\n          ...action.payload.learningProgress\n        };\n      }\n      \n      if (action.payload.personalPreferences) {\n        state.conversationContext.personalPreferences = {\n          ...state.conversationContext.personalPreferences,\n          ...action.payload.personalPreferences\n        };\n      }\n    },\n    \n    incrementInteractionCount: (state) => {\n      state.conversationContext.totalInteractions++;\n      state.conversationContext.lastInteractionTime = Date.now();\n    },\n    \n    // Privacy & Consent\n    updatePrivacyConsent: (state, action: PayloadAction<{\n      consentGiven: boolean;\n      dataProcessingAllowed: Partial<AIState['privacy']['dataProcessingAllowed']>;\n    }>) => {\n      state.privacy.consentGiven = action.payload.consentGiven;\n      \n      if (action.payload.dataProcessingAllowed) {\n        state.privacy.dataProcessingAllowed = {\n          ...state.privacy.dataProcessingAllowed,\n          ...action.payload.dataProcessingAllowed\n        };\n      }\n    },\n    \n    setParentalConsentRequired: (state, action: PayloadAction<boolean>) => {\n      state.privacy.parentalConsentRequired = action.payload;\n    },\n    \n    // Performance\n    updatePerformanceMetrics: (state, action: PayloadAction<{\n      responseTime?: number;\n      cacheHitRate?: number;\n      networkStatus?: AIState['performance']['networkStatus'];\n      serviceHealth?: Partial<AIState['performance']['serviceHealth']>;\n    }>) => {\n      if (action.payload.responseTime) {\n        // Update average response time\n        const totalRequests = state.conversationContext.totalInteractions;\n        state.performance.averageResponseTime = \n          (state.performance.averageResponseTime * (totalRequests - 1) + action.payload.responseTime) / totalRequests;\n      }\n      \n      if (action.payload.cacheHitRate !== undefined) {\n        state.performance.cacheHitRate = action.payload.cacheHitRate;\n      }\n      \n      if (action.payload.networkStatus) {\n        state.performance.networkStatus = action.payload.networkStatus;\n        state.performance.offlineMode = action.payload.networkStatus === 'offline';\n      }\n      \n      if (action.payload.serviceHealth) {\n        state.performance.serviceHealth = {\n          ...state.performance.serviceHealth,\n          ...action.payload.serviceHealth\n        };\n      }\n    },\n    \n    // Learning & Achievements\n    addCurrentTopic: (state, action: PayloadAction<string>) => {\n      if (!state.learning.currentTopics.includes(action.payload)) {\n        state.learning.currentTopics.push(action.payload);\n      }\n    },\n    \n    removeCurrentTopic: (state, action: PayloadAction<string>) => {\n      state.learning.currentTopics = state.learning.currentTopics.filter(\n        topic => topic !== action.payload\n      );\n    },\n    \n    addAchievement: (state, action: PayloadAction<{\n      id: string;\n      title: string;\n      description: string;\n    }>) => {\n      const achievement = {\n        ...action.payload,\n        timestamp: Date.now()\n      };\n      \n      // Check if achievement already exists\n      if (!state.learning.achievements.some(a => a.id === achievement.id)) {\n        state.learning.achievements.push(achievement);\n      }\n    },\n    \n    updateRecommendations: (state, action: PayloadAction<{\n      suggestedTopics?: string[];\n      learningObjectives?: string[];\n      characterRecommendations?: string[];\n    }>) => {\n      if (action.payload.suggestedTopics) {\n        state.learning.recommendations.suggestedTopics = action.payload.suggestedTopics;\n      }\n      \n      if (action.payload.learningObjectives) {\n        state.learning.recommendations.learningObjectives = action.payload.learningObjectives;\n      }\n      \n      if (action.payload.characterRecommendations) {\n        state.learning.recommendations.characterRecommendations = action.payload.characterRecommendations;\n      }\n    },\n    \n    // Navigation\n    updateNavigationSuggestions: (state, action: PayloadAction<string[]>) => {\n      state.navigation.suggestions = action.payload;\n    },\n    \n    setPendingNavigation: (state, action: PayloadAction<{\n      page: string;\n      reason: string;\n    } | null>) => {\n      if (action.payload) {\n        state.navigation.autoNavigation.pendingNavigation = {\n          ...action.payload,\n          timestamp: Date.now()\n        };\n      } else {\n        state.navigation.autoNavigation.pendingNavigation = null;\n      }\n    },\n    \n    setAutoNavigationEnabled: (state, action: PayloadAction<boolean>) => {\n      state.navigation.autoNavigation.enabled = action.payload;\n    },\n    \n    updateContextualPrompts: (state, action: PayloadAction<string[]>) => {\n      state.navigation.contextualPrompts = action.payload;\n    },\n    \n    // General Reset\n    resetAIState: () => {\n      return { \n        ...initialState, \n        conversationContext: {\n          ...initialState.conversationContext,\n          sessionId: `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`\n        }\n      };\n    }\n  },\n  \n  extraReducers: (builder) => {\n    // Process AI Interaction\n    builder\n      .addCase(processAIInteraction.pending, (state) => {\n        state.currentInteraction.processing = true;\n        state.currentInteraction.error = null;\n      })\n      .addCase(processAIInteraction.fulfilled, (state, action) => {\n        const response = action.payload;\n        \n        state.currentInteraction.processing = false;\n        \n        // Update emotional analysis\n        if (response.emotional) {\n          state.emotionalAnalysis.currentEmotion = {\n            primary: response.emotional.detectedEmotion,\n            intensity: 0.5, // Default intensity\n            confidence: 0.8, // Default confidence\n            timestamp: Date.now()\n          };\n          \n          state.emotionalAnalysis.supportLevel = response.emotional.supportLevel as any;\n          state.emotionalAnalysis.adaptations = response.emotional.adaptations;\n        }\n        \n        // Update learning progress\n        if (response.learning) {\n          if (response.learning.educationalContent?.topic) {\n            state.learning.currentTopics = [response.learning.educationalContent.topic];\n          }\n          \n          if (response.learning.achievements) {\n            response.learning.achievements.forEach((achievement: string) => {\n              state.learning.achievements.push({\n                id: `achievement_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n                title: achievement,\n                description: achievement,\n                timestamp: Date.now()\n              });\n            });\n          }\n        }\n        \n        // Update navigation\n        if (response.navigation) {\n          state.navigation.suggestions = response.navigation.suggestions;\n          \n          if (response.navigation.autoNavigation) {\n            state.navigation.autoNavigation.pendingNavigation = {\n              page: response.navigation.autoNavigation.page,\n              reason: response.navigation.autoNavigation.reason,\n              timestamp: Date.now()\n            };\n          }\n        }\n        \n        // Update follow-up suggestions\n        if (response.followUp) {\n          state.navigation.contextualPrompts = response.followUp.contextualPrompts;\n          \n          if (response.followUp.learningOpportunities) {\n            state.learning.recommendations.suggestedTopics = response.followUp.learningOpportunities;\n          }\n        }\n        \n        // Update performance metrics\n        if (response.performance) {\n          state.performance.averageResponseTime = response.performance.responseTime;\n          state.performance.cacheHitRate = response.performance.cacheUsed ? \n            state.performance.cacheHitRate + 1 : state.performance.cacheHitRate;\n        }\n        \n        // Add voice to queue if available\n        if (response.response.audio) {\n          state.voiceSynthesis.queue.push({\n            id: `audio_${Date.now()}`,\n            text: response.response.text,\n            character: response.response.character,\n            emotion: response.response.emotion,\n            priority: 'medium'\n          });\n        }\n        \n        // Increment interaction count\n        state.conversationContext.totalInteractions++;\n        state.conversationContext.lastInteractionTime = Date.now();\n      })\n      .addCase(processAIInteraction.rejected, (state, action) => {\n        state.currentInteraction.processing = false;\n        state.currentInteraction.error = action.payload as string;\n      });\n    \n    // Speech Recognition\n    builder\n      .addCase(startSpeechRecognition.pending, (state) => {\n        state.speechRecognition.listening = true;\n        state.speechRecognition.error = null;\n      })\n      .addCase(startSpeechRecognition.fulfilled, (state) => {\n        state.speechRecognition.listening = true;\n      })\n      .addCase(startSpeechRecognition.rejected, (state, action) => {\n        state.speechRecognition.listening = false;\n        state.speechRecognition.error = action.payload as string;\n      });\n    \n    builder\n      .addCase(stopSpeechRecognition.fulfilled, (state) => {\n        state.speechRecognition.listening = false;\n        state.speechRecognition.transcript = '';\n        state.speechRecognition.confidence = 0;\n      });\n    \n    // Privacy Consent\n    builder\n      .addCase(requestPrivacyConsent.fulfilled, (state, action) => {\n        const response = action.payload;\n        \n        state.privacy.parentalConsentRequired = response.parentalConsentRequired;\n        \n        if (!response.consentRequired) {\n          state.privacy.consentGiven = true;\n          \n          // Enable permissions based on temporary permissions\n          if (response.temporaryPermissions?.includes('voice_data')) {\n            state.privacy.dataProcessingAllowed.voice = true;\n          }\n          if (response.temporaryPermissions?.includes('emotional_analysis')) {\n            state.privacy.dataProcessingAllowed.emotion = true;\n          }\n        }\n      });\n  }\n});\n\nexport const {\n  // Session Management\n  initializeAISession,\n  \n  // Interaction State\n  startInteraction,\n  endInteraction,\n  setInteractionProcessing,\n  setInteractionError,\n  \n  // Speech Recognition\n  setSpeechTranscript,\n  setSpeechCommand,\n  setSpeechError,\n  \n  // Voice Synthesis\n  addToVoiceQueue,\n  removeFromVoiceQueue,\n  setCurrentAudio,\n  updateVoiceSettings,\n  \n  // Emotional Analysis\n  updateCurrentEmotion,\n  updateEmotionalAdaptations,\n  setSupportLevel,\n  addSafetyAlert,\n  clearSafetyAlerts,\n  \n  // Conversation Context\n  updateConversationContext,\n  incrementInteractionCount,\n  \n  // Privacy & Consent\n  updatePrivacyConsent,\n  setParentalConsentRequired,\n  \n  // Performance\n  updatePerformanceMetrics,\n  \n  // Learning & Achievements\n  addCurrentTopic,\n  removeCurrentTopic,\n  addAchievement,\n  updateRecommendations,\n  \n  // Navigation\n  updateNavigationSuggestions,\n  setPendingNavigation,\n  setAutoNavigationEnabled,\n  updateContextualPrompts,\n  \n  // General Reset\n  resetAIState\n} = aiSlice.actions;\n\nexport default aiSlice.reducer;