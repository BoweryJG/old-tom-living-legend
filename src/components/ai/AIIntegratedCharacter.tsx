import React, { useState, useEffect, useCallback, useRef } from 'react';\nimport { Box, Typography, Fade, IconButton, Tooltip, Alert } from '@mui/material';\nimport { Mic, MicOff, VolumeUp, VolumeOff, Psychology, Chat } from '@mui/icons-material';\nimport { animated, useSpring } from '@react-spring/web';\n\nimport { useAppSelector, useAppDispatch } from '@/store';\nimport { \n  processAIInteraction, \n  startSpeechRecognition, \n  stopSpeechRecognition,\n  startInteraction,\n  endInteraction,\n  initializeAISession,\n  setSpeechTranscript,\n  setSpeechCommand,\n  addToVoiceQueue,\n  setCurrentAudio,\n  requestPrivacyConsent,\n  updateVoiceSettings\n} from '@/store/slices/aiSlice';\nimport { speechRecognitionService } from '@/services/speechRecognitionService';\n\ninterface AIIntegratedCharacterProps {\n  characterId: 'old-tom' | 'george-davidson' | 'child-narrator';\n  size?: 'small' | 'medium' | 'large';\n  interactive?: boolean;\n  enableVoice?: boolean;\n  enableEmotionalAI?: boolean;\n  context?: string;\n  childAge?: number;\n  onAIResponse?: (response: string) => void;\n  showControls?: boolean;\n  autoInitialize?: boolean;\n}\n\nconst characterConfig = {\n  'old-tom': {\n    name: 'Old Tom',\n    emoji: 'üêã',\n    color: '#1565C0',\n    gradientColors: ['rgba(21, 101, 192, 0.1)', 'rgba(2, 119, 189, 0.2)'],\n    greetings: [\n      \"Welcome to my ocean realm, young explorer!\",\n      \"The tides have brought you to me...\",\n      \"Ah, another soul seeking stories from the deep!\",\n      \"Come closer, and I'll share the ocean's secrets.\"\n    ]\n  },\n  'george-davidson': {\n    name: 'George Davidson',\n    emoji: '‚öì',\n    color: '#8D6E63',\n    gradientColors: ['rgba(141, 110, 99, 0.1)', 'rgba(121, 85, 72, 0.2)'],\n    greetings: [\n      \"G'day there, young mate! Welcome aboard our story.\",\n      \"Well hello there, little sailor! Ready to hear some tales?\",\n      \"Ah, a curious young soul! Come here and I'll tell you about the old days.\"\n    ]\n  },\n  'child-narrator': {\n    name: 'Young Explorer',\n    emoji: 'üë¶',\n    color: '#FF9800',\n    gradientColors: ['rgba(255, 152, 0, 0.1)', 'rgba(245, 124, 0, 0.2)'],\n    greetings: [\n      \"Oh wow! Are you here to learn about Old Tom too?\",\n      \"Hi there! I can't wait to show you what I've discovered!\",\n      \"Welcome! You're going to love meeting Old Tom!\"\n    ]\n  }\n};\n\nexport const AIIntegratedCharacter: React.FC<AIIntegratedCharacterProps> = ({\n  characterId,\n  size = 'medium',\n  interactive = true,\n  enableVoice = true,\n  enableEmotionalAI = true,\n  context = 'general',\n  childAge,\n  onAIResponse,\n  showControls = true,\n  autoInitialize = true\n}) => {\n  const dispatch = useAppDispatch();\n  const config = characterConfig[characterId];\n  \n  // Local state\n  const [isHovered, setIsHovered] = useState(false);\n  const [showGreeting, setShowGreeting] = useState(false);\n  const [currentGreeting, setCurrentGreeting] = useState('');\n  const [aiResponse, setAiResponse] = useState('');\n  const audioRef = useRef<HTMLAudioElement | null>(null);\n  \n  // AI State from Redux\n  const aiState = useAppSelector(state => state.ai);\n  const {\n    currentInteraction,\n    speechRecognition,\n    voiceSynthesis,\n    emotionalAnalysis,\n    conversationContext,\n    privacy,\n    performance\n  } = aiState;\n  \n  // Character state\n  const { characters } = useAppSelector(state => state.character);\n  const character = characters[characterId];\n  \n  // Size configurations\n  const sizeConfig = {\n    small: { width: 80, height: 80, fontSize: '1.5rem' },\n    medium: { width: 150, height: 150, fontSize: '2rem' },\n    large: { width: 200, height: 200, fontSize: '3rem' },\n  };\n  const dimensions = sizeConfig[size];\n  \n  // Initialize AI session\n  useEffect(() => {\n    if (autoInitialize && !conversationContext.sessionId) {\n      const sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n      dispatch(initializeAISession({ sessionId, childAge }));\n      \n      // Show greeting after initialization\n      setTimeout(() => {\n        const greeting = config.greetings[Math.floor(Math.random() * config.greetings.length)];\n        setCurrentGreeting(greeting);\n        setShowGreeting(true);\n        \n        // Auto-hide greeting\n        setTimeout(() => setShowGreeting(false), 5000);\n      }, 1000);\n    }\n  }, [autoInitialize, conversationContext.sessionId, childAge, config.greetings, dispatch]);\n  \n  // Speech recognition setup\n  useEffect(() => {\n    if (!enableVoice || !speechRecognition.supported) return;\n    \n    const handleSpeechResult = (result: any) => {\n      dispatch(setSpeechTranscript({\n        transcript: result.transcript,\n        confidence: result.confidence\n      }));\n      \n      if (result.isFinal) {\n        if (result.command) {\n          dispatch(setSpeechCommand(result.command));\n          handleVoiceCommand(result.command);\n        } else if (result.transcript.trim()) {\n          // Process as natural language input\n          handleVoiceInput(result.transcript);\n        }\n      }\n    };\n    \n    const handleSpeechError = (error: Error) => {\n      console.error('Speech recognition error:', error);\n    };\n    \n    speechRecognitionService.addListener('result', handleSpeechResult);\n    speechRecognitionService.addErrorListener(handleSpeechError);\n    \n    return () => {\n      speechRecognitionService.removeListener('result', handleSpeechResult);\n      speechRecognitionService.removeErrorListener(handleSpeechError);\n    };\n  }, [enableVoice, speechRecognition.supported, dispatch]);\n  \n  // Voice synthesis queue processing\n  useEffect(() => {\n    if (voiceSynthesis.queue.length > 0 && !voiceSynthesis.speaking && voiceSynthesis.settings.enabled) {\n      const nextItem = voiceSynthesis.queue[0];\n      if (nextItem.character === characterId) {\n        playAudioResponse(nextItem);\n      }\n    }\n  }, [voiceSynthesis.queue, voiceSynthesis.speaking, voiceSynthesis.settings.enabled, characterId]);\n  \n  // Handle AI interactions\n  const handleAIInteraction = useCallback(async (inputText?: string, interactionType: string = 'casual_chat') => {\n    if (currentInteraction.processing) return;\n    \n    // Check privacy consent first\n    if (!privacy.consentGiven) {\n      try {\n        await dispatch(requestPrivacyConsent({\n          childAge: childAge || 7,\n          requiredConsents: ['basic_interaction', 'character_chat']\n        })).unwrap();\n      } catch (error) {\n        console.error('Privacy consent failed:', error);\n        return;\n      }\n    }\n    \n    dispatch(startInteraction({\n      type: interactionType as any,\n      character: characterId,\n      method: inputText ? 'text' : 'gesture'\n    }));\n    \n    try {\n      const response = await dispatch(processAIInteraction({\n        input: { \n          text: inputText || `Hello ${config.name}!`, \n          context \n        },\n        interaction: { \n          type: interactionType, \n          character: characterId, \n          method: inputText ? 'text' : 'gesture'\n        },\n        userProfile: { \n          age: childAge,\n          emotionalState: emotionalAnalysis.currentEmotion?.primary \n        },\n        environment: { \n          currentPage: 'character_interaction',\n          sessionDuration: Date.now() - conversationContext.sessionStartTime\n        }\n      })).unwrap();\n      \n      if (response.success && response.response.text) {\n        setAiResponse(response.response.text);\n        onAIResponse?.(response.response.text);\n        \n        // Auto-hide AI response after 8 seconds\n        setTimeout(() => setAiResponse(''), 8000);\n      }\n    } catch (error) {\n      console.error('AI interaction failed:', error);\n    } finally {\n      dispatch(endInteraction());\n    }\n  }, [currentInteraction.processing, privacy.consentGiven, childAge, characterId, config.name, context, emotionalAnalysis.currentEmotion?.primary, conversationContext.sessionStartTime, onAIResponse, dispatch]);\n  \n  const handleVoiceInput = useCallback(async (transcript: string) => {\n    await handleAIInteraction(transcript, 'question');\n  }, [handleAIInteraction]);\n  \n  const handleVoiceCommand = useCallback(async (command: any) => {\n    if (command.type === `talk_to_${characterId.replace('-', '_')}`) {\n      await handleAIInteraction();\n    } else if (command.type === 'ask_about_marine_life' && command.parameters.subject) {\n      await handleAIInteraction(`Tell me about ${command.parameters.subject}`, 'question');\n    }\n  }, [handleAIInteraction, characterId]);\n  \n  const handleVoiceToggle = useCallback(async () => {\n    if (!enableVoice || !speechRecognition.supported) return;\n    \n    if (speechRecognition.listening) {\n      await dispatch(stopSpeechRecognition()).unwrap();\n    } else {\n      await dispatch(startSpeechRecognition(context)).unwrap();\n    }\n  }, [enableVoice, speechRecognition.supported, speechRecognition.listening, context, dispatch]);\n  \n  const playAudioResponse = useCallback((audioItem: any) => {\n    // For demo purposes, using browser's speech synthesis\n    if ('speechSynthesis' in window && voiceSynthesis.settings.enabled) {\n      const utterance = new SpeechSynthesisUtterance(audioItem.text);\n      \n      // Character-specific voice settings\n      if (characterId === 'old-tom') {\n        utterance.rate = 0.7;\n        utterance.pitch = 0.6;\n      } else if (characterId === 'george-davidson') {\n        utterance.rate = 0.8;\n        utterance.pitch = 0.8;\n      } else if (characterId === 'child-narrator') {\n        utterance.rate = 1.0;\n        utterance.pitch = 1.2;\n      }\n      \n      utterance.volume = voiceSynthesis.settings.volume;\n      \n      utterance.onstart = () => {\n        dispatch(setCurrentAudio({\n          id: audioItem.id,\n          character: audioItem.character,\n          duration: audioItem.text.length * 100\n        }));\n      };\n      \n      utterance.onend = () => {\n        dispatch(setCurrentAudio(null));\n      };\n      \n      speechSynthesis.speak(utterance);\n    }\n  }, [characterId, voiceSynthesis.settings.enabled, voiceSynthesis.settings.volume, dispatch]);\n  \n  const toggleVoice = useCallback(() => {\n    dispatch(updateVoiceSettings({\n      enabled: !voiceSynthesis.settings.enabled\n    }));\n  }, [voiceSynthesis.settings.enabled, dispatch]);\n  \n  // Animations\n  const floatAnimation = useSpring({\n    from: { transform: 'translateY(0px)' },\n    to: async (next) => {\n      while (true) {\n        await next({ transform: 'translateY(-8px)' });\n        await next({ transform: 'translateY(0px)' });\n      }\n    },\n    config: { duration: 3000 },\n  });\n  \n  const hoverAnimation = useSpring({\n    transform: isHovered ? 'scale(1.05)' : 'scale(1)',\n    filter: isHovered ? 'brightness(1.1)' : 'brightness(1)',\n    config: { tension: 200, friction: 20 },\n  });\n  \n  const speakingAnimation = useSpring({\n    transform: voiceSynthesis.speaking ? 'scale(1.02)' : 'scale(1)',\n    filter: voiceSynthesis.speaking ? 'brightness(1.05) saturate(1.2)' : 'brightness(1) saturate(1)',\n    config: { tension: 150, friction: 15 },\n  });\n  \n  const emotionalAnimation = useSpring({\n    borderColor: emotionalAnalysis.currentEmotion ? \n      (emotionalAnalysis.currentEmotion.primary === 'excited' ? '#FFD700' :\n       emotionalAnalysis.currentEmotion.primary === 'gentle' ? '#87CEEB' :\n       emotionalAnalysis.currentEmotion.primary === 'wise' ? '#DDA0DD' : config.color) :\n      config.color,\n    boxShadow: speechRecognition.listening ? \n      `0 0 20px ${config.color}66, 0 0 40px ${config.color}33` :\n      `0 8px 32px ${config.color}33`,\n    config: { duration: 1000 }\n  });\n  \n  return (\n    <Box\n      sx={{\n        position: 'relative',\n        display: 'flex',\n        flexDirection: 'column',\n        alignItems: 'center',\n        cursor: interactive ? 'pointer' : 'default',\n        userSelect: 'none',\n      }}\n      onClick={() => interactive && handleAIInteraction()}\n      onMouseEnter={() => setIsHovered(true)}\n      onMouseLeave={() => setIsHovered(false)}\n    >\n      {/* Privacy Notice */}\n      {!privacy.consentGiven && (\n        <Alert \n          severity=\"info\" \n          sx={{ \n            position: 'absolute', \n            top: -60, \n            left: '50%', \n            transform: 'translateX(-50%)',\n            fontSize: '0.75rem',\n            maxWidth: 250\n          }}\n        >\n          Click to start AI conversation (parental consent may be required)\n        </Alert>\n      )}\n      \n      {/* AI Controls */}\n      {showControls && enableVoice && speechRecognition.supported && (\n        <Box\n          sx={{\n            position: 'absolute',\n            top: -45,\n            right: -25,\n            display: 'flex',\n            gap: 0.5,\n            zIndex: 10,\n          }}\n        >\n          <Tooltip title={speechRecognition.listening ? 'Stop Listening' : 'Start Voice Chat'}>\n            <IconButton\n              size=\"small\"\n              onClick={(e) => {\n                e.stopPropagation();\n                handleVoiceToggle();\n              }}\n              sx={{\n                width: 32,\n                height: 32,\n                backgroundColor: speechRecognition.listening ? '#FF9800' : '#2196F3',\n                color: 'white',\n                '&:hover': {\n                  backgroundColor: speechRecognition.listening ? '#F57C00' : '#1976D2',\n                },\n              }}\n            >\n              {speechRecognition.listening ? <MicOff fontSize=\"small\" /> : <Mic fontSize=\"small\" />}\n            </IconButton>\n          </Tooltip>\n          \n          <Tooltip title={voiceSynthesis.settings.enabled ? 'Mute Voice' : 'Enable Voice'}>\n            <IconButton\n              size=\"small\"\n              onClick={(e) => {\n                e.stopPropagation();\n                toggleVoice();\n              }}\n              sx={{\n                width: 32,\n                height: 32,\n                backgroundColor: voiceSynthesis.settings.enabled ? '#4CAF50' : '#9E9E9E',\n                color: 'white',\n                '&:hover': {\n                  backgroundColor: voiceSynthesis.settings.enabled ? '#388E3C' : '#757575',\n                },\n              }}\n            >\n              {voiceSynthesis.settings.enabled ? <VolumeUp fontSize=\"small\" /> : <VolumeOff fontSize=\"small\" />}\n            </IconButton>\n          </Tooltip>\n        </Box>\n      )}\n      \n      {/* Main Character */}\n      <animated.div\n        style={{\n          ...floatAnimation,\n          ...hoverAnimation,\n          ...speakingAnimation,\n        }}\n      >\n        <animated.div style={emotionalAnimation}>\n          <Box\n            sx={{\n              width: dimensions.width,\n              height: dimensions.height,\n              position: 'relative',\n              borderRadius: '50%',\n              background: `linear-gradient(135deg, ${config.gradientColors[0]}, ${config.gradientColors[1]})`,\n              display: 'flex',\n              alignItems: 'center',\n              justifyContent: 'center',\n              border: '3px solid',\n              borderColor: config.color,\n              transition: 'all 0.3s ease',\n              '&:hover': interactive ? {\n                transform: 'scale(1.02)',\n              } : {},\n            }}\n          >\n            {/* Character Emoji/Icon */}\n            <Box\n              sx={{\n                fontSize: dimensions.fontSize,\n                filter: 'drop-shadow(0 2px 4px rgba(0,0,0,0.2))',\n              }}\n            >\n              {config.emoji}\n            </Box>\n            \n            {/* Status Indicators */}\n            {voiceSynthesis.speaking && (\n              <Box\n                sx={{\n                  position: 'absolute',\n                  top: -5,\n                  right: -5,\n                  width: 18,\n                  height: 18,\n                  borderRadius: '50%',\n                  background: '#4CAF50',\n                  border: '2px solid white',\n                  animation: 'pulse 1s ease-in-out infinite',\n                  '@keyframes pulse': {\n                    '0%': { transform: 'scale(1)', opacity: 1 },\n                    '50%': { transform: 'scale(1.2)', opacity: 0.7 },\n                    '100%': { transform: 'scale(1)', opacity: 1 },\n                  },\n                }}\n              />\n            )}\n            \n            {speechRecognition.listening && (\n              <Box\n                sx={{\n                  position: 'absolute',\n                  top: -5,\n                  left: -5,\n                  width: 18,\n                  height: 18,\n                  borderRadius: '50%',\n                  background: '#FF9800',\n                  border: '2px solid white',\n                  animation: 'bounce 1s ease-in-out infinite',\n                  '@keyframes bounce': {\n                    '0%, 100%': { transform: 'translateY(0)' },\n                    '50%': { transform: 'translateY(-3px)' },\n                  },\n                }}\n              />\n            )}\n            \n            {currentInteraction.processing && (\n              <Box\n                sx={{\n                  position: 'absolute',\n                  bottom: -5,\n                  right: -5,\n                  width: 16,\n                  height: 16,\n                  borderRadius: '50%',\n                  background: '#2196F3',\n                  border: '2px solid white',\n                  display: 'flex',\n                  alignItems: 'center',\n                  justifyContent: 'center',\n                }}\n              >\n                <Psychology fontSize=\"inherit\" sx={{ fontSize: '10px', color: 'white' }} />\n              </Box>\n            )}\n            \n            {/* Emotion Indicator */}\n            {emotionalAnalysis.currentEmotion && (\n              <Box\n                sx={{\n                  position: 'absolute',\n                  bottom: -10,\n                  left: '50%',\n                  transform: 'translateX(-50%)',\n                  fontSize: '1rem',\n                  filter: 'drop-shadow(0 2px 4px rgba(0,0,0,0.2))',\n                }}\n              >\n                {emotionalAnalysis.currentEmotion.primary === 'excited' && 'üéâ'}\n                {emotionalAnalysis.currentEmotion.primary === 'wise' && 'üßô‚Äç‚ôÇÔ∏è'}\n                {emotionalAnalysis.currentEmotion.primary === 'gentle' && 'üòå'}\n                {emotionalAnalysis.currentEmotion.primary === 'curious' && 'üåü'}\n                {emotionalAnalysis.currentEmotion.primary === 'happy' && 'üòä'}\n                {emotionalAnalysis.currentEmotion.primary === 'protective' && 'üõ°Ô∏è'}\n              </Box>\n            )}\n          </Box>\n        </animated.div>\n      </animated.div>\n      \n      {/* Speech Transcript */}\n      {speechRecognition.transcript && speechRecognition.listening && (\n        <Fade in timeout={200}>\n          <Box\n            sx={{\n              position: 'absolute',\n              top: -90,\n              left: '50%',\n              transform: 'translateX(-50%)',\n              background: 'rgba(255, 255, 255, 0.95)',\n              backdropFilter: 'blur(10px)',\n              borderRadius: 2,\n              padding: 1.5,\n              maxWidth: 250,\n              textAlign: 'center',\n              boxShadow: '0 4px 16px rgba(0,0,0,0.1)',\n              border: `1px solid ${config.color}`,\n            }}\n          >\n            <Typography variant=\"caption\" sx={{ color: config.color, fontWeight: 500 }}>\n              \"{speechRecognition.transcript}\"\n            </Typography>\n          </Box>\n        </Fade>\n      )}\n      \n      {/* Greeting */}\n      {showGreeting && currentGreeting && (\n        <Fade in timeout={500}>\n          <Box\n            sx={{\n              position: 'absolute',\n              top: speechRecognition.transcript ? -140 : -90,\n              left: '50%',\n              transform: 'translateX(-50%)',\n              background: 'rgba(255, 255, 255, 0.95)',\n              backdropFilter: 'blur(10px)',\n              borderRadius: 3,\n              padding: 2,\n              maxWidth: 280,\n              textAlign: 'center',\n              boxShadow: '0 4px 16px rgba(0,0,0,0.1)',\n              border: `1px solid ${config.color}`,\n              zIndex: 5,\n              '&::after': {\n                content: '\"\"',\n                position: 'absolute',\n                bottom: -8,\n                left: '50%',\n                transform: 'translateX(-50%)',\n                width: 0,\n                height: 0,\n                borderLeft: '8px solid transparent',\n                borderRight: '8px solid transparent',\n                borderTop: '8px solid rgba(255, 255, 255, 0.95)',\n              },\n            }}\n          >\n            <Typography\n              variant={size === 'large' ? 'body1' : 'body2'}\n              sx={{\n                color: config.color,\n                fontWeight: 500,\n                lineHeight: 1.4,\n              }}\n            >\n              {currentGreeting}\n            </Typography>\n          </Box>\n        </Fade>\n      )}\n      \n      {/* AI Response */}\n      {aiResponse && (\n        <Fade in timeout={500}>\n          <Box\n            sx={{\n              position: 'absolute',\n              top: (showGreeting || speechRecognition.transcript) ? -180 : -90,\n              left: '50%',\n              transform: 'translateX(-50%)',\n              background: `${config.color}DD`,\n              color: 'white',\n              borderRadius: 3,\n              padding: 2,\n              maxWidth: 320,\n              textAlign: 'center',\n              boxShadow: '0 4px 16px rgba(0,0,0,0.2)',\n              zIndex: 10,\n              '&::after': {\n                content: '\"\"',\n                position: 'absolute',\n                bottom: -8,\n                left: '50%',\n                transform: 'translateX(-50%)',\n                width: 0,\n                height: 0,\n                borderLeft: '8px solid transparent',\n                borderRight: '8px solid transparent',\n                borderTop: `8px solid ${config.color}DD`,\n              },\n            }}\n          >\n            <Typography\n              variant={size === 'large' ? 'body1' : 'body2'}\n              sx={{\n                fontWeight: 500,\n                lineHeight: 1.4,\n              }}\n            >\n              {aiResponse}\n            </Typography>\n          </Box>\n        </Fade>\n      )}\n      \n      {/* Interactive Hints */}\n      {interactive && isHovered && !currentInteraction.processing && (\n        <Fade in timeout={200}>\n          <Typography\n            variant=\"caption\"\n            sx={{\n              mt: 1,\n              color: config.color,\n              fontWeight: 500,\n              textAlign: 'center',\n              display: 'flex',\n              alignItems: 'center',\n              gap: 0.5,\n            }}\n          >\n            <Chat fontSize=\"inherit\" />\n            Click to chat with {config.name}\n          </Typography>\n        </Fade>\n      )}\n      \n      {currentInteraction.processing && (\n        <Fade in timeout={200}>\n          <Typography\n            variant=\"caption\"\n            sx={{\n              mt: 1,\n              color: '#2196F3',\n              fontWeight: 500,\n              textAlign: 'center',\n              display: 'flex',\n              alignItems: 'center',\n              gap: 0.5,\n            }}\n          >\n            <Psychology fontSize=\"inherit\" />\n            {config.name} is thinking...\n          </Typography>\n        </Fade>\n      )}\n      \n      {/* Performance indicator for debugging */}\n      {process.env.NODE_ENV === 'development' && performance.averageResponseTime > 0 && (\n        <Typography\n          variant=\"caption\"\n          sx={{\n            position: 'absolute',\n            bottom: -40,\n            fontSize: '0.7rem',\n            color: '#666',\n            textAlign: 'center',\n          }}\n        >\n          Avg: {Math.round(performance.averageResponseTime)}ms\n        </Typography>\n      )}\n    </Box>\n  );\n};\n\nexport default AIIntegratedCharacter;